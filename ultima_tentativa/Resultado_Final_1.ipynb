{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from datetime import time\n",
    "import matplotlib.pyplot as pplot\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.cross_validation import ShuffleSplit, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data_process_final/treino_final.csv')\n",
    "df_teste = pd.read_csv('data_process_final/teste_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove = df_train.loc[(df_train['day'] >= 1) & (df_train['day'] <= 7) ]\n",
    "\n",
    "df_train = df_train.drop(df_remove.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['volume_proximo']\n",
    "del df_teste['volume_proximo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['volume_proximo_2']\n",
    "del df_teste['volume_proximo_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adiciona_media_desvio_por_dia(df):\n",
    "    df['media_volume_hora_dia'] = df.groupby(['direction', 'tollgate_id', 'day', 'hour'])[\"volume\"].transform(np.mean)\n",
    "    df['desvio_padrao_hora_dia'] = df.groupby(['direction', 'tollgate_id', 'day', 'hour'])[\"volume\"].transform(np.std)\n",
    "    df['desvio_padrao_hora_dia'].fillna(df.groupby(['direction', 'tollgate_id', 'day', 'hour'])[\"volume\"].transform(np.mean), inplace=True)\n",
    "    df['min_volume_hora_dia'] = df.groupby(['direction', 'tollgate_id', 'day', 'hour'])['volume'].transform(np.min)\n",
    "    df['max_volume_hora_dia'] = df.groupby(['direction', 'tollgate_id', 'day', 'hour'])['volume'].transform(np.max)\n",
    "    df['mediana_volume_hora_dia'] = df.groupby(['direction', 'tollgate_id', 'day', 'hour'])['volume'].transform(np.median)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = adiciona_media_desvio_por_dia(df_train)\n",
    "df_teste= adiciona_media_desvio_por_dia(df_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adiciona_media_desvio_por_janela_dia_semana_1(df):\n",
    "    df['time'] = pd.to_datetime(df['time'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    df['date'] = df['time'].dt.date\n",
    "    mask = (df['time'] > '2016-09-18 00:00:00') & (df['time'] < '2016-09-26 00:00:00')\n",
    "    df = df.loc[mask]\n",
    "    df['min_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.min)\n",
    "    df['max_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.max)\n",
    "    df['mediana_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.median)\n",
    "    df['media_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.mean)\n",
    "    df['desvio_padrao_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.std)\n",
    "    df['desvio_padrao_weekday'].fillna(df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.mean), inplace=True)\n",
    "    return df\n",
    "\n",
    "def adiciona_media_desvio_por_janela_dia_semana_2(df):\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df['time'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    df['date'] = df['time'].dt.date\n",
    "    mask2 = (df['time'] > '2016-09-18 00:00:00') & (df['time'] < '2016-10-10 00:00:00')\n",
    "    df = df.loc[mask2]\n",
    "    df['min_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.min)\n",
    "    df['max_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.max)\n",
    "    df['mediana_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.median)\n",
    "    df['media_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.mean)\n",
    "    df['desvio_padrao_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.std)\n",
    "    df['desvio_padrao_weekday'].fillna(df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.mean), inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def adiciona_media_desvio_por_janela_dia_semana_3(df):\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df['time'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    df['date'] = df['time'].dt.date\n",
    "    mask3 = (df['time'] > '2016-09-18 00:00:00') & (df['time'] < '2016-10-17 00:00:00')\n",
    "    df = df.loc[mask3]\n",
    "    df['min_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.min)\n",
    "    df['max_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.max)\n",
    "    df['mediana_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.median)\n",
    "    df['media_volume_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.mean)\n",
    "    df['desvio_padrao_weekday'] = df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.std)\n",
    "    df['desvio_padrao_weekday'].fillna(df.groupby(['am_pm', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.mean), inplace=True)\n",
    "    return df\n",
    "\n",
    "def adiciona_media_desvio_por_janela_dia_semana_4(df):   \n",
    "    df['time'] = pd.to_datetime(df['time'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    df['date'] = df['time'].dt.date\n",
    "    mask4 = (df['time'] > '2016-09-18 00:00:00') & (df['time'] < '2016-10-25 00:00:00')\n",
    "    df = df.loc[mask4]\n",
    "    df['min_volume_weekday'] = df.groupby(['time_window', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.min)\n",
    "    df['max_volume_weekday'] = df.groupby(['time_window', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.max)\n",
    "    df['mediana_volume_weekday'] = df.groupby(['time_window', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.median)\n",
    "    df['media_volume_weekday'] = df.groupby(['time_window', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.mean)\n",
    "    df['desvio_padrao_weekday'] = df.groupby(['time_window', 'week','direction', 'tollgate_id'])[\"volume\"].transform(np.std)\n",
    "    df['desvio_padrao_weekday'].fillna(df.groupby(['time_window', 'week', 'direction', 'tollgate_id'])[\"volume\"].transform(np.mean), inplace=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matheuspds/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_train_a_25 =adiciona_media_desvio_por_janela_dia_semana_1(df_train)\n",
    "df_train_a_10 = adiciona_media_desvio_por_janela_dia_semana_2(df_train)\n",
    "df_train_a_17 = adiciona_media_desvio_por_janela_dia_semana_3(df_train)\n",
    "df_train_a_24 = adiciona_media_desvio_por_janela_dia_semana_4(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_list = [df_train_a_25, df_train_a_10, df_train_a_17, df_train_a_24]\n",
    "df_train_para_agregar = pd.concat(df_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste['min_volume_weekday'] = df_train_a_24['min_volume_weekday']\n",
    "df_teste['max_volume_weekday'] = df_train_a_24['max_volume_weekday']\n",
    "df_teste['mediana_volume_weekday'] = df_train_a_24['mediana_volume_weekday']\n",
    "df_teste['media_volume_weekday'] = df_train_a_24['media_volume_weekday']\n",
    "df_teste['desvio_padrao_weekday'] = df_train_a_24['desvio_padrao_weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#media do volume do dia naquela tollgate naquela direcao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medidas_volume_tollgate_direction_am_pm(df):\n",
    "    df['min_volume_dia_am_pm'] = df.groupby(['day', 'direction', 'tollgate_id', 'am_pm'])[\"volume\"].transform(np.min)\n",
    "    df['max_volume_dia_am_pm'] = df.groupby(['day', 'direction', 'tollgate_id', 'am_pm'])[\"volume\"].transform(np.max)\n",
    "    df['mediana_volume_dia_am_pm'] = df.groupby(['day', 'direction', 'tollgate_id', 'am_pm'])[\"volume\"].transform(np.median)\n",
    "    df['media_volume_dia_am_pm'] = df.groupby(['day', 'direction', 'tollgate_id', 'am_pm'])[\"volume\"].transform(np.mean)\n",
    "    df['desvio_padrao_am_pm'] = df.groupby(['day','direction', 'tollgate_id', 'am_pm'])[\"volume\"].transform(np.std)\n",
    "    df['desvio_padrao_am_pm'].fillna(df.groupby(['day', 'direction', 'tollgate_id', 'am_pm'])[\"volume\"].transform(np.mean), inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_para_agregar = medidas_volume_tollgate_direction_am_pm(df_train_para_agregar)\n",
    "df_teste = medidas_volume_tollgate_direction_am_pm(df_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_format():\n",
    "    #pd_volume_train = pd_volume_train.set_index(['time'])\n",
    "    #pd_volume_test = pd_volume_test.set_index(['time'])\n",
    "    #volume_train = v_train.groupby(['time_window','tollgate_id','direction','date', 'hour']).size().reset_index().rename(columns = {0:'volume'})\n",
    "    #volume_test = v_test.groupby(['time_window','tollgate_id','direction','date', 'hour']).size().reset_index().rename(columns = {0:'volume'})\n",
    "    #print(volume_train)                \n",
    "    x = pd.Series(df_train_para_agregar['time_window'].unique())\n",
    "    s = pd.Series(range(len(x)),index = x.values)\n",
    "    df_train_para_agregar['window_n'] = df_train_para_agregar['time_window'].map(s)\n",
    "    df_teste['window_n'] = df_teste['time_window'].map(s)\n",
    "#        print vol_test.tail()\n",
    "    #volume_train['weekday'] = v_train['weekday']\n",
    "    #volume_test['weekday'] = v_test['weekday']\n",
    "    \n",
    "    feature_train = df_train_para_agregar.drop('volume', axis = 1)\n",
    "    feature_test = df_teste.drop('volume',axis = 1)\n",
    "    values_train = df_train_para_agregar['volume'].values\n",
    "    values_test = df_teste['volume'].values\n",
    "    \n",
    "    return feature_train, feature_test, values_train, values_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train, feature_test, values_train, values_test = feature_format()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'tollgate_id', 'direction', 'time_window', 'day', 'hour',\n",
       "       'minute', 'week', 'weekend', 'am_pm', 'volume_anterior',\n",
       "       'volume_anterior_2', 'avg_vol_dia_semana', 'desvio_padrao',\n",
       "       'media_volume_hora_dia', 'desvio_padrao_hora_dia',\n",
       "       'min_volume_hora_dia', 'max_volume_hora_dia', 'mediana_volume_hora_dia',\n",
       "       'date', 'min_volume_weekday', 'max_volume_weekday',\n",
       "       'mediana_volume_weekday', 'media_volume_weekday',\n",
       "       'desvio_padrao_weekday', 'min_volume_dia_am_pm', 'max_volume_dia_am_pm',\n",
       "       'mediana_volume_dia_am_pm', 'media_volume_dia_am_pm',\n",
       "       'desvio_padrao_am_pm', 'window_n'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_cubic = RandomForestRegressor(n_estimators=500, max_depth=10, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_cubic.fit(feature_train[['tollgate_id','direction','week', 'weekend','volume_anterior', 'volume_anterior_2', 'am_pm', 'window_n', 'desvio_padrao_hora_dia', 'mediana_volume_hora_dia', 'max_volume_hora_dia', 'media_volume_hora_dia', 'min_volume_hora_dia', 'media_volume_dia_am_pm', 'max_volume_dia_am_pm', 'mediana_volume_dia_am_pm', 'min_volume_dia_am_pm', 'desvio_padrao_am_pm', 'media_volume_weekday', 'desvio_padrao_weekday']], values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor_cubic.predict(feature_test[['tollgate_id','direction','week', 'weekend','volume_anterior', 'volume_anterior_2', 'am_pm', 'window_n', 'desvio_padrao_hora_dia', 'mediana_volume_hora_dia', 'max_volume_hora_dia', 'media_volume_hora_dia', 'min_volume_hora_dia', 'media_volume_dia_am_pm', 'max_volume_dia_am_pm', 'mediana_volume_dia_am_pm', 'min_volume_dia_am_pm', 'desvio_padrao_am_pm', 'media_volume_weekday', 'desvio_padrao_weekday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12953690488310818"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(values_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.186625150957875"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred, values_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "    'max_features': [None],\n",
    "    'n_estimators': [200, 300, 500, 800, 1200, 1500, 1800]\n",
    "    #colocar um intervalo mais logico. Treino teste e validacao (tira uma parte do treino para validacao, e os\n",
    "    # e eu nao posso fazer isso pra proxima janela de treino)\n",
    "    #volume proximo nao pode ser utilizado\n",
    "    # a media de dias da semana anterior\n",
    "    # max altura, max numero de features, n_estimadores (100, 200, 300, 400)\n",
    "    # max altura (80, 90,100, 110)\n",
    "    # n_features deixa o numero de features fixo que eu tenho passa o auto\n",
    "    # random_state tirar do decision tree\n",
    "    #fazer isso\n",
    "    #falar primeiro do decision tree antes mesmo do random forest\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 4, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 77 candidates, totalling 308 fits\n",
      "[CV] max_depth=10, max_features=None, n_estimators=200 ...............\n",
      "[CV] max_depth=10, max_features=None, n_estimators=200 ...............\n",
      "[CV] max_depth=10, max_features=None, n_estimators=200 ...............\n",
      "[CV] max_depth=10, max_features=None, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=200, total=   7.8s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=200, total=   8.1s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=200, total=   8.2s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=200, total=   8.4s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=300, total=  13.7s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=300, total=  13.2s\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=300, total=  13.0s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=300, total=  13.3s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=500 ...............\n",
      "[CV] max_depth=10, max_features=None, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=500, total=  21.0s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=800 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=500, total=  21.3s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=800 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=500, total=  21.5s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=800 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=500, total=  21.7s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=800 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=800, total=  34.1s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1200 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=800, total=  34.7s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1200 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=800, total=  35.3s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1200 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=800, total=  35.2s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1200 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1200, total=  47.6s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1500 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1200, total=  47.5s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1500 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1200, total=  49.1s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1500 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1200, total=  49.3s\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1500 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1500, total= 1.0min\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1800 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1500, total= 1.0min\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1800 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1500, total= 1.0min\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1800 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1500, total= 1.0min\n",
      "[CV] max_depth=10, max_features=None, n_estimators=1800 ..............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1800, total= 1.4min\n",
      "[CV] max_depth=20, max_features=None, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1800, total= 1.3min\n",
      "[CV] max_depth=20, max_features=None, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1800, total= 1.4min\n",
      "[CV] max_depth=20, max_features=None, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=None, n_estimators=1800, total= 1.4min\n",
      "[CV] max_depth=20, max_features=None, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=200, total=  15.6s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=200, total=  16.1s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=200, total=  16.1s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=200, total=  15.7s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=300, total=  21.2s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=500 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, max_features=None, n_estimators=300, total=  20.9s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=300, total=  21.0s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=300, total=  20.8s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=500, total=  35.3s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=800 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=500, total=  35.0s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=800 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=500, total=  34.7s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=800 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=500, total=  34.7s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=800 ...............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=800, total=  55.8s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=1200 ..............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=800, total=  55.2s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=1200 ..............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=800, total=  56.9s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=1200 ..............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=800, total=  55.8s\n",
      "[CV] max_depth=20, max_features=None, n_estimators=1200 ..............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=1200, total= 1.4min\n",
      "[CV] max_depth=20, max_features=None, n_estimators=1500 ..............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=1200, total= 1.4min\n",
      "[CV] max_depth=20, max_features=None, n_estimators=1500 ..............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=1200, total= 1.4min\n",
      "[CV] max_depth=20, max_features=None, n_estimators=1500 ..............\n",
      "[CV]  max_depth=20, max_features=None, n_estimators=1200, total= 1.4min\n",
      "[CV] max_depth=20, max_features=None, n_estimators=1500 ..............\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-43886b85518c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tollgate_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'direction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hour'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'week'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weekend'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'volume_anterior'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'volume_anterior_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'am_pm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'window_n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'desvio_padrao_hora_dia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mediana_volume_hora_dia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_volume_hora_dia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'media_volume_hora_dia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_volume_hora_dia'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(feature_train[['tollgate_id','direction', 'hour', 'week', 'weekend','volume_anterior', 'volume_anterior_2', 'am_pm', 'window_n', 'desvio_padrao_hora_dia', 'mediana_volume_hora_dia', 'max_volume_hora_dia', 'media_volume_hora_dia', 'min_volume_hora_dia']], values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'max_features': None, 'n_estimators': 1200}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 10.7845 degrees.\n",
      "Accuracy = 76.51%.\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, feature_test[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']], values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 1.68%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_cubic = RandomForestRegressor(n_estimators=500, max_features='sqrt', random_state=10, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "           oob_score=True, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_cubic.fit(feature_train[[1,2,3,'direction','week', 'weekend','volume_anterior', 'volume_anterior_2', 'am_pm', 'window_n', 'desvio_padrao_hora_dia', 'mediana_volume_hora_dia', 'max_volume_hora_dia', 'media_volume_hora_dia', 'min_volume_hora_dia']], values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor_cubic.predict(feature_test[['tollgate_id','direction','week', 'weekend','volume_anterior', 'volume_anterior_2', 'am_pm', 'window_n', 'desvio_padrao_hora_dia', 'mediana_volume_hora_dia', 'max_volume_hora_dia', 'media_volume_hora_dia', 'min_volume_hora_dia']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14857108140804984"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(values_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.417343747884098"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred, values_test))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ADABOOSTING REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADABooster(param_grid, n_jobs): \n",
    "    estimator = AdaBoostRegressor() \n",
    "    cv = ShuffleSplit(feature_train[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']].shape[0], test_size=0.2) \n",
    "    classifier = GridSearchCV(estimator=estimator, cv=4, param_grid=param_grid, n_jobs=n_jobs) \n",
    "    classifier.fit(feature_train[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']], values_train) \n",
    "    print (\"Best Estimator learned through GridSearch\")\n",
    "    print (classifier.best_estimator_)\n",
    "    return cv, classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator learned through GridSearch\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=0.005,\n",
      "         loss='exponential', n_estimators=1200, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "param_grid={'n_estimators':[100, 300, 500, 800, 1200], \n",
    "            'learning_rate': [0.1, 0.05, 0.01, 0.005], \n",
    "            'loss':['linear', 'square', 'exponential']}\n",
    "n_jobs=4 \n",
    "\n",
    "cv,best_est=ADABooster(param_grid, n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = AdaBoostRegressor(n_estimators=1200, learning_rate=0.005, loss='exponential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=0.005,\n",
       "         loss='exponential', n_estimators=1200, random_state=None)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(feature_train[['tollgate_id','direction','week', 'weekend','volume_anterior', 'volume_anterior_2', 'am_pm', 'window_n', 'desvio_padrao_hora_dia', 'mediana_volume_hora_dia', 'max_volume_hora_dia', 'media_volume_hora_dia', 'min_volume_hora_dia', 'media_volume_dia_am_pm', 'max_volume_dia_am_pm', 'mediana_volume_dia_am_pm', 'min_volume_dia_am_pm', 'desvio_padrao_am_pm', 'media_volume_weekday', 'desvio_padrao_weekday']], values_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.46036113e-05,\n",
       "       0.00000000e+00, 4.90057580e-03, 3.37452797e-03, 0.00000000e+00,\n",
       "       7.94052041e-03, 0.00000000e+00, 6.97806457e-03, 2.38786604e-02,\n",
       "       9.50440266e-01, 2.46278120e-03])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = regr.predict(feature_test[['tollgate_id','direction','week', 'weekend','volume_anterior', 'volume_anterior_2', 'am_pm', 'window_n', 'desvio_padrao_hora_dia', 'mediana_volume_hora_dia', 'max_volume_hora_dia', 'media_volume_hora_dia', 'min_volume_hora_dia', 'media_volume_dia_am_pm', 'max_volume_dia_am_pm', 'mediana_volume_dia_am_pm', 'min_volume_dia_am_pm', 'desvio_padrao_am_pm', 'media_volume_weekday', 'desvio_padrao_weekday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324050491518168"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(feature_train[['tollgate_id','direction','week', 'weekend','volume_anterior', 'volume_anterior_2', 'am_pm', 'window_n', 'desvio_padrao_hora_dia', 'mediana_volume_hora_dia', 'max_volume_hora_dia', 'media_volume_hora_dia', 'min_volume_hora_dia']], values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1737088333453783"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(values_test, y_pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.741637344837978"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(values_test, y_pred_ada))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "regr = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 50),\n",
    "                         n_estimators=300, random_state = rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(feature_train[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']], values_train)\n",
    "\n",
    "y_pred = regr.predict(feature_test[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.896148431565727"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(values_test, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20620277519594812"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(values_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo o GBRT COM PARAMETROS MAIS SIMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt=GradientBoostingRegressor(n_estimators=100) \n",
    "gbrt.fit(feature_train[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']], values_train)\n",
    "\n",
    "y_pred_gbrt=gbrt.predict(feature_test[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2620375772444925"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(values_test, y_pred_gbrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientBooster(param_grid, n_jobs): \n",
    "    estimator = GradientBoostingRegressor() \n",
    "    cv = ShuffleSplit(feature_train[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']].shape[0], n_iter=10, test_size=0.2) \n",
    "    classifier = GridSearchCV(estimator=estimator, cv=cv, param_grid=param_grid, n_jobs=n_jobs) \n",
    "    classifier.fit(feature_train[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']], values_train) \n",
    "    print (\"Best Estimator learned through GridSearch\")\n",
    "    print (classifier.best_estimator_)\n",
    "    return cv, classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator learned through GridSearch\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=6, max_features=1.0,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=3,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid={'n_estimators':[100], \n",
    "            'learning_rate': [0.1], \n",
    "            'max_depth':[6], \n",
    "            'min_samples_leaf':[3],\n",
    "            'max_features':[1.0]}\n",
    "n_jobs=4 \n",
    "\n",
    "cv,best_est=GradientBooster(param_grid, n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters\n",
      "---------------------------\n",
      "n_estimators: 100\n",
      "max_depth: 6\n",
      "Learning Rate: 0.1\n",
      "min_samples_leaf: 3\n",
      "max_features: 1.0\n",
      "Train R-squared: 0.97\n"
     ]
    }
   ],
   "source": [
    "print (\"Best Estimator Parameters\") \n",
    "print(\"---------------------------\" )\n",
    "print (\"n_estimators: %d\" %best_est.n_estimators) \n",
    "print (\"max_depth: %d\" %best_est.max_depth) \n",
    "print (\"Learning Rate: %.1f\" %best_est.learning_rate) \n",
    "print (\"min_samples_leaf: %d\" %best_est.min_samples_leaf) \n",
    "print (\"max_features: %.1f\" %best_est.max_features) \n",
    "\n",
    "print (\"Train R-squared: %.2f\" %best_est.score(feature_train[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']], values_train) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=6, max_features=1.0,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = best_est\n",
    "estimator.fit(feature_train[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']], values_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R-squared: 0.97\n",
      "Test R-squared: 0.86\n"
     ]
    }
   ],
   "source": [
    "print (\"Train R-squared: %.2f\" %estimator.score(feature_train[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']], values_train)  )\n",
    "\n",
    "print (\"Test R-squared: %.2f\" %estimator.score(feature_test[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']], values_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, max_depth=best_est.max_depth, learning_rate=best_est.learning_rate, min_samples_leaf=best_est.min_samples_leaf, max_features=best_est.max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=6, max_features=1.0,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(feature_train[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']], values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbrt_oficial = estimator.predict(feature_test[['tollgate_id', 'direction','week', 'am_pm', 'volume_anterior', 'volume_anterior_2', 'volume_proximo', 'volume_proximo_2', 'avg_vol_dia_semana', 'desvio_padrao', 'window_n']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21357123313872148"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(values_test, y_pred_gbrt_oficial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.16351207391079"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(values_test, y_pred_gbrt_oficial))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "regressor_cubic_g = GradientBoostingRegressor(n_estimators=250, learning_rate=0.05, min_samples_split=15,\n",
    "                                                min_samples_leaf=2, max_depth=5, subsample=0.8,\n",
    "                                                random_state=10, loss=\"lad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_cubic_g.fit(feature_train[['tollgate_id','direction','week', 'weekend','volume_anterior', 'volume_anterior_2', 'am_pm', 'window_n', 'desvio_padrao_hora_dia', 'mediana_volume_hora_dia', 'max_volume_hora_dia', 'media_volume_hora_dia', 'min_volume_hora_dia', 'media_volume_dia_am_pm', 'max_volume_dia_am_pm', 'mediana_volume_dia_am_pm', 'min_volume_dia_am_pm', 'desvio_padrao_am_pm', 'media_volume_weekday', 'desvio_padrao_weekday']], values_train)\n",
    "yhat = regressor_cubic_g.predict(feature_test[['tollgate_id','direction','week', 'weekend','volume_anterior', 'volume_anterior_2', 'am_pm', 'window_n', 'desvio_padrao_hora_dia', 'mediana_volume_hora_dia', 'max_volume_hora_dia', 'media_volume_hora_dia', 'min_volume_hora_dia', 'media_volume_dia_am_pm', 'max_volume_dia_am_pm', 'mediana_volume_dia_am_pm', 'min_volume_dia_am_pm', 'desvio_padrao_am_pm', 'media_volume_weekday', 'desvio_padrao_weekday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1435833002442322"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(values_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.285118290770122"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(values_test, yhat))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
