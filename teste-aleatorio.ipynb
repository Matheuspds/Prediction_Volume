{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a38954de97b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from pandas.tseries.offsets import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# description of the feature:\n",
    "# Traffic Volume through the Tollgates\n",
    "# time           datatime        the time when a vehicle passes the tollgate\n",
    "# tollgate_id    string          ID of the tollgate\n",
    "# direction      string           0:entry, 1:exit\n",
    "# vehicle_model  int             this number ranges from 0 to 7, which indicates the capacity of the vehicle(bigger the higher)\n",
    "# has_etc        string          does the vehicle use ETC (Electronic Toll Collection) device? 0: No, 1: Yes\n",
    "# vehicle_type   string          vehicle type: 0-passenger vehicle, 1-cargo vehicle\n",
    "\n",
    "\n",
    "def preprocessing():\n",
    "    '''\n",
    "    预处理训练集\n",
    "    '''\n",
    "    volume_df = pd.read_csv(\"dataset/volume(table 6)_training.csv\")\n",
    "\n",
    "    # 替换所有有标签含义的数字\n",
    "    volume_df['tollgate_id'] = volume_df['tollgate_id'].replace({1: \"1S\", 2: \"2S\", 3: \"3S\"})\n",
    "    volume_df['direction'] = volume_df['direction'].replace({0: \"entry\", 1: \"exit\"})\n",
    "    volume_df['has_etc'] = volume_df['has_etc'].replace({0: \"No\", 1: \"Yes\"})\n",
    "    volume_df['vehicle_type'] = volume_df['vehicle_type'].replace({0: \"passenger\", 1: \"carge\"})\n",
    "    volume_df['time'] = volume_df['time'].apply(lambda x: pd.Timestamp(x))\n",
    "\n",
    "    # 承载量：1-默认客车，2-默认货车，3-默认货车，4-默认客车\n",
    "    # 承载量大于等于5的为货运汽车，所有承载量为0的车都类型不明\n",
    "    volume_df = volume_df.sort_values(by=\"vehicle_model\")\n",
    "    vehicle_model0 = volume_df[volume_df['vehicle_model'] == 0].fillna(\"No\")\n",
    "    vehicle_model1 = volume_df[volume_df['vehicle_model'] == 1].fillna(\"passenger\")\n",
    "    vehicle_model2 = volume_df[volume_df['vehicle_model'] == 2].fillna(\"carge\")\n",
    "    vehicle_model3 = volume_df[volume_df['vehicle_model'] == 3].fillna(\"carge\")\n",
    "    vehicle_model4 = volume_df[volume_df['vehicle_model'] == 4].fillna(\"passenger\")\n",
    "    vehicle_model5 = volume_df[volume_df['vehicle_model'] >= 5].fillna(\"carge\")\n",
    "    volume_df = pd.concat([vehicle_model0, vehicle_model1, vehicle_model2, vehicle_model3, vehicle_model4, vehicle_model5])\n",
    "\n",
    "    '''\n",
    "    处理预测集\n",
    "    '''\n",
    "    volume_test = pd.read_csv(\"dataset/volume(table 6)_test1.csv\")\n",
    "    # 替换所有有标签含义的数字\n",
    "    volume_test['tollgate_id'] = volume_test['tollgate_id'].replace({1:\"1S\", 2:\"2S\", 3:\"3S\"})\n",
    "    volume_test['direction'] = volume_test['direction'].replace({0:\"entry\", 1:\"exit\"})\n",
    "    volume_test['has_etc'] = volume_test['has_etc'].replace({0:\"No\", 1:\"Yes\"})\n",
    "    volume_test['vehicle_type'] = volume_test['vehicle_type'].replace({0:\"passenger\", 1:\"carge\"})\n",
    "    volume_test['time'] = volume_test['time'].apply(lambda x: pd.Timestamp(x))\n",
    "\n",
    "    # 承载量：1-默认客车，2-默认货车，3-默认货车，4-默认客车\n",
    "    # 承载量大于等于5的为货运汽车，所有承载量为0的车都类型不明\n",
    "    volume_test = volume_test.sort_values(by=\"vehicle_model\")\n",
    "    vehicle_model0 = volume_test[volume_test['vehicle_model'] == 0].fillna(\"No\")\n",
    "    vehicle_model1 = volume_test[volume_test['vehicle_model'] == 1].fillna(\"passenger\")\n",
    "    vehicle_model2 = volume_test[volume_test['vehicle_model'] == 2].fillna(\"cargo\")\n",
    "    vehicle_model3 = volume_test[volume_test['vehicle_model'] == 3].fillna(\"cargo\")\n",
    "    vehicle_model4 = volume_test[volume_test['vehicle_model'] == 4].fillna(\"passenger\")\n",
    "    vehicle_model5 = volume_test[volume_test['vehicle_model'] >= 5].fillna(\"cargo\")\n",
    "    volume_test = pd.concat([vehicle_model0, vehicle_model1, vehicle_model2, vehicle_model3, vehicle_model4, vehicle_model5])\n",
    "    return volume_df, volume_test\n",
    "\n",
    "\n",
    "def modeling():\n",
    "    volume_train, volume_test = preprocessing()\n",
    "    result_df = pd.DataFrame()\n",
    "    tollgate_list = [\"1S\", \"2S\", \"3S\"]\n",
    "    # tollgate_list = [\"2S\"]\n",
    "    for tollgate_id in tollgate_list:\n",
    "\n",
    "        # 创建之和流量，20分钟跨度有关系的训练集\n",
    "        def divide_train_by_direction(volume_df):\n",
    "            volume_time_entry = pd.Series(data=1, index=\n",
    "            volume_df.loc[(volume_df['tollgate_id'] == tollgate_id) & (volume_df['direction'] == \"entry\"), :]['time'])\n",
    "            volume_time_entry = volume_time_entry.resample(\"20T\").sum()\n",
    "            volume_entry = pd.DataFrame(index=volume_time_entry.index)\n",
    "            volume_entry['volume'] = np.log(volume_time_entry + 1)\n",
    "\n",
    "            volume_time_exit = pd.Series(data=1, index=\n",
    "            volume_df.loc[(volume_df['tollgate_id'] == tollgate_id) & (volume_df['direction'] == \"exit\"), :]['time'])\n",
    "            volume_time_exit = volume_time_exit.resample(\"20T\").sum()\n",
    "            volume_exit = pd.DataFrame(index=volume_time_exit.index)\n",
    "            volume_exit['volume'] = np.log(volume_time_exit + 1)\n",
    "            return volume_entry.fillna(0), volume_exit.fillna(0)\n",
    "\n",
    "        # 创建训练集，总的要求就是以前两个小时数据为训练集，用迭代式预测方法\n",
    "        # 例如8点-10点的数据预测10点20,8点-10点20预测10点40……，每一次预测使用的都是独立的（可能模型一样）的模型\n",
    "        # 现在开始构建训练集\n",
    "        # 第一个训练集特征是所有两个小时（以20分钟为一个单位）的数据，因变量是该两小时之后20分钟的流量\n",
    "        # 第二个训练集，特征是所有两个小时又20分钟（以20分钟为一个单位）的数据，因变量是该两个小时之后20分钟的流量\n",
    "        # 以此类推训练12个GBDT模型，其中entry 6个，exit 6个\n",
    "        def generate_models(volume_entry, volume_exit):\n",
    "            # best_rate = 0.1\n",
    "            # best_n_estimator = 3000\n",
    "            # param_grid = [\n",
    "            #                 {'max_depth':[3, 4], 'min_samples_leaf':[1],\n",
    "            #                  'learning_rate':[best_rate + 0.01 * i for i in range(-2, 4, 1)],\n",
    "            #                  'loss':['lad'],\n",
    "            #                  'n_estimators':[best_n_estimator + i * 200 for i in range(-2, 3, 1)],\n",
    "            #                  'max_features':[1.0]}\n",
    "            #             ]\n",
    "            param_grid = [\n",
    "                {'max_depth':[3], 'min_samples_leaf':[1],\n",
    "                 'learning_rate':[0.1], 'loss':['lad'], 'n_estimators':[3000], 'max_features':[1.0]}\n",
    "            ]\n",
    "\n",
    "            # 这是交叉验证的评分函数\n",
    "            def scorer(estimator, X, y):\n",
    "                predict_arr = estimator.predict(X)\n",
    "                y_arr = y\n",
    "                # result = (np.abs(predict_arr - y_arr) / y_arr).sum() / len(y)\n",
    "                result = (np.abs(1 - np.exp(predict_arr - y_arr))).sum() / len(y)\n",
    "                return result\n",
    "\n",
    "            #这是用训练集做预测时的评分函数\n",
    "            def scorer2(estimator, X, y):\n",
    "                predict_arr = estimator.predict(X)\n",
    "                # result = (np.abs(predict_arr - y) / y).sum()\n",
    "                result = (np.abs(1 - np.exp(predict_arr - y))).sum()\n",
    "                return result\n",
    "\n",
    "            models_entry = []\n",
    "            train_entry_len = 0\n",
    "            train_entry_score = 0\n",
    "            for j in range(6):\n",
    "                train_df = pd.DataFrame()\n",
    "                for i in range(len(volume_entry) - 6 - j):\n",
    "                    df_temp = volume_entry.iloc[i:i + 6, 0]\n",
    "                    df_temp = df_temp.append(pd.Series(volume_entry.iloc[i + 6 + j, 0]))\n",
    "                    df_temp.index = range(7)\n",
    "                    train_df = train_df.append(df_temp, ignore_index=True)\n",
    "                train_df = train_df[train_df.iloc[:, 6] > 0]\n",
    "                train_X = train_df.iloc[:, :6].fillna(0)\n",
    "                train_y = train_df.iloc[:, 6].fillna(0)\n",
    "                model = GradientBoostingRegressor()\n",
    "                clf = GridSearchCV(model, param_grid, refit=True, scoring=scorer)\n",
    "                clf.fit(train_X, train_y)\n",
    "                print (\"Best GBDT param is :\", clf.best_params_)\n",
    "                train_entry_len += len(train_y)\n",
    "                train_entry_score += scorer2(clf.best_estimator_, train_X, train_y)\n",
    "                models_entry.append(clf.best_estimator_)\n",
    "            print (\"Best Score is :\", train_entry_score / train_entry_len)\n",
    "\n",
    "            # 注意！！！！2号收费站只有entry方向没有exit方向\n",
    "            if len(volume_exit) == 0:\n",
    "                return models_entry, []\n",
    "\n",
    "\n",
    "            models_exit = []\n",
    "            train_exit_len = 0\n",
    "            train_exit_score = 0\n",
    "            for j in range(6):\n",
    "                train_df = pd.DataFrame()\n",
    "                for i in range(len(volume_exit) - 6 - j):\n",
    "                    df_temp = volume_exit.iloc[i:i + 6, 0]\n",
    "                    df_temp = df_temp.append(pd.Series(volume_exit.iloc[i + 6 + j, 0]))\n",
    "                    df_temp.index = range(7)\n",
    "                    train_df = train_df.append(df_temp, ignore_index=True)\n",
    "                train_df = train_df[train_df.iloc[:, 6] > 0]\n",
    "                train_X = train_df.iloc[:, :6].fillna(0)\n",
    "                train_y = train_df.iloc[:, 6].fillna(0)\n",
    "                model = GradientBoostingRegressor()\n",
    "                clf = GridSearchCV(model, param_grid, refit=True, scoring=scorer)\n",
    "                clf.fit(train_X, train_y)\n",
    "                print (\"Best GBDT param is :\", clf.best_params_)\n",
    "                train_exit_len += len(train_y)\n",
    "                train_exit_score += scorer2(clf.best_estimator_, train_X, train_y)\n",
    "                models_exit.append(clf.best_estimator_)\n",
    "            print (\"Best Score is :\", train_exit_score / train_exit_len)\n",
    "\n",
    "            return models_entry, models_exit\n",
    "\n",
    "        # 创建车流量预测集，20分钟跨度有关系的预测集\n",
    "        def divide_test_by_direction(volume_test):\n",
    "            volume_time_entry_test = pd.Series(data=1,\n",
    "                                               index=volume_test.loc[(volume_test['tollgate_id'] == tollgate_id) & (\n",
    "                                               volume_test['direction'] == \"entry\"), :]['time'])\n",
    "            volume_time_entry_test = volume_time_entry_test.resample(\"20T\").sum()\n",
    "            volume_entry_test = pd.DataFrame(index=volume_time_entry_test.index)\n",
    "            volume_entry_test['volume'] = np.log(volume_time_entry_test + 1)\n",
    "            volume_entry_test = volume_entry_test.dropna()\n",
    "\n",
    "            volume_time_exit_test = pd.Series(data=1,\n",
    "                                              index=volume_test.loc[(volume_test['tollgate_id'] == tollgate_id) & (\n",
    "                                                  volume_test['direction'] == \"exit\"), :]['time'])\n",
    "            volume_time_exit_test = volume_time_exit_test.resample(\"20T\").sum()\n",
    "            volume_exit_test = pd.DataFrame(index=volume_time_exit_test.index)\n",
    "            volume_exit_test['volume'] = np.log(volume_time_exit_test + 1)\n",
    "            volume_exit_test = volume_exit_test.dropna()\n",
    "            return volume_entry_test, volume_exit_test\n",
    "\n",
    "        # 转换预测集，将预测集转换成与训练集格式相同的格式\n",
    "        def predict(volume_entry_test, volume_exit_test, models_entry, models_exit):\n",
    "            # （entry方向）\n",
    "            test_entry_df = pd.DataFrame()\n",
    "            i = 0\n",
    "            while i < len(volume_entry_test) - 5:\n",
    "                df_temp = volume_entry_test.iloc[i:i + 6, 0].T\n",
    "                df_temp.index = range(6)\n",
    "                df_temp.name = volume_entry_test.index[i]\n",
    "                test_entry_df = test_entry_df.append(df_temp)\n",
    "                i = i + 6\n",
    "\n",
    "            predict_test_entry = pd.DataFrame()\n",
    "            predict_test_entry = predict_test_entry.append(test_entry_df)\n",
    "            for i in range(6):\n",
    "                test_y = models_entry[i].predict(test_entry_df)\n",
    "                predict_test_entry[i + 6] = test_y\n",
    "\n",
    "            # （exit方向）\n",
    "            test_exit_df = pd.DataFrame()\n",
    "            if len(models_exit) == 0:\n",
    "                return predict_test_entry, test_exit_df\n",
    "            i = 0\n",
    "            while i < len(volume_exit_test) - 5:\n",
    "                df_temp = volume_exit_test.iloc[i:i + 6, 0].T\n",
    "                df_temp.index = range(6)\n",
    "                df_temp.name = volume_exit_test.index[i]\n",
    "                test_exit_df = test_exit_df.append(df_temp)\n",
    "                i = i + 6\n",
    "\n",
    "            predict_test_exit = pd.DataFrame()\n",
    "            predict_test_exit = predict_test_exit.append(test_exit_df)\n",
    "            for i in range(6):\n",
    "                test_y = models_exit[i].predict(test_exit_df)\n",
    "                predict_test_exit[i + 6] = test_y\n",
    "\n",
    "            return predict_test_entry, predict_test_exit\n",
    "\n",
    "\n",
    "        # 将预测数据转换成输出文件的格式\n",
    "        def transform_predict(predict_original, direction, tollgate_id):\n",
    "            result = pd.DataFrame()\n",
    "            for i in range(len(predict_original)):\n",
    "                time_basic = predict_original.index[i]\n",
    "                for j in range(6, 12, 1):\n",
    "                    time_window = \"[\" + str(time_basic + DateOffset(minutes=j * 20)) + \",\" + str(\n",
    "                        time_basic + DateOffset(minutes=(j + 1) * 20)) + \")\"\n",
    "                    series = pd.Series({\"tollgate_id\": tollgate_id,\n",
    "                                        \"time_window\": time_window,\n",
    "                                        \"direction\": direction,\n",
    "                                        \"volume\": \"%.2f\" % (np.exp(predict_original.iloc[i, j]) - 1)})\n",
    "                    series.name = i + j - 6\n",
    "                    result = result.append(series)\n",
    "            return result\n",
    "\n",
    "        volume_entry_train, volume_exit_train = divide_train_by_direction(volume_train)\n",
    "        models_entry, models_exit = generate_models(volume_entry_train, volume_exit_train)\n",
    "        volume_entry_test, volume_exit_test = divide_test_by_direction(volume_test)\n",
    "        predict_original_entry, predict_original_exit = predict(volume_entry_test,\n",
    "                                                                volume_exit_test,\n",
    "                                                                models_entry,\n",
    "                                                                models_exit)\n",
    "        result_df = result_df.append(transform_predict(predict_original_entry, \"entry\", tollgate_id))\n",
    "        result_df = result_df.append(transform_predict(predict_original_exit, \"exit\", tollgate_id))\n",
    "\n",
    "    return result_df\n",
    "\n",
    "result = modeling()\n",
    "result_df = pd.DataFrame()\n",
    "result_df[\"tollgate_id\"] = result[\"tollgate_id\"].replace({\"1S\": 1, \"2S\": 2, \"3S\": 3})\n",
    "result_df[\"time_window\"] = result[\"time_window\"]\n",
    "result_df[\"direction\"] = result[\"direction\"].replace({\"entry\": 0, \"exit\": 1})\n",
    "result_df['volume'] = result[\"volume\"]\n",
    "result_df.to_csv(\"volume_predict_result_aleatorio.csv\", encoding=\"utf8\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
